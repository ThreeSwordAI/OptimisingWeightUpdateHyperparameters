:actor_name:ray_tune_trainable
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.32]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.31]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.3] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.3]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.26]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.26]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.34]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.31]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.28]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.26]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.26]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.27]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.27]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.31]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.29]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.31]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.31]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.26]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.3] 0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.3]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.33]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.35]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.31]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.22]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.33]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.26]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.37]0:   0%|          | 2/1000 [00:01<06:04,  2.74it/s, Loss/Training=2.28]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.28]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.35]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.3] 0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.3]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.34]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.32]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.28]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.27]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.37]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.28]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=2.29]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.29]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.29]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.31]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.34]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.22]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.3] 0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.23]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.32]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.29]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.35]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.28]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.28]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.29]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.26]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.3] 0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.31]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.28]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.29]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.33]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.27]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.32]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=2.32]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.32]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.28]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.33]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.26]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.31]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.35]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.26]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.26]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.26]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.26]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=2.28]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.28]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.28]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.32]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.3] 0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.32]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.3] 0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.28]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.31]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.27]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.3] 0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.33]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.33]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.3] 0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.33]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.27]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.32]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.3] 0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.27]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.28]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.28]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.33]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=2.31]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.31]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.28]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.34]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.3] 0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.29]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.3] 0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.26]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.28]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.27]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.33]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=2.33]0:   1%|          | 9/1000 [00:03<06:16,  2.63it/s, Loss/Training=2.33]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpe04920
[INFO 2025-01-27 15:39:10,684] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpe04920
Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 3.8976614475250244, '_episodes_total': None}
[INFO 2025-01-27 15:39:10,684] trainable.py: 913  Current state after restoring: {'_iteration': 100, '_timesteps_total': None, '_time_total': 3.8976614475250244, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.35]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.29]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.28]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.31]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.27]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.27]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.3] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.29]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.26]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.28]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.28]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.25]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.27]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.28]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.26]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.26]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.32]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.32]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.33]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.29]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=2.34]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.34]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.32]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.28]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.21]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.29]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.29]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.25]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=2.3] 0:   0%|          | 2/1000 [00:01<06:03,  2.74it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.26]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.31]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.26]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.26]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.22]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.33]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.29]0:   0%|          | 3/1000 [00:01<05:42,  2.91it/s, Loss/Training=2.25]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.25]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.26]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.27]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.28]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.22]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.32]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.26]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.28]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.26]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.33]0:   0%|          | 4/1000 [00:01<05:31,  3.01it/s, Loss/Training=2.27]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.27]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.27]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.27]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.29]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.26]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.26]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.29]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.28]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.3] 0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.25]0:   0%|          | 5/1000 [00:01<05:28,  3.02it/s, Loss/Training=2.34]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.34]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.34]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.25]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.27]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.32]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.3] 0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.25]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.32]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.24]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.25]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.27]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.27]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.31]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.22]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.27]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.22]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.26]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.3] 0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.24]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.31]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.28]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.23]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.23]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.28]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.3] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.26]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.2] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.27]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.27]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.26]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.25]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.2] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=2.22]0:   1%|          | 9/1000 [00:02<05:19,  3.10it/s, Loss/Training=2.22]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.23]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.2] 0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.25]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.33]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.28]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.28]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.24]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.28]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.24]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=2.17]0:   1%|          | 9/1000 [00:03<06:23,  2.59it/s, Loss/Training=2.17]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpb2160a
[INFO 2025-01-27 15:39:38,612] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpb2160a
Current state after restoring: {'_iteration': 200, '_timesteps_total': None, '_time_total': 7.776991128921509, '_episodes_total': None}
[INFO 2025-01-27 15:39:38,612] trainable.py: 913  Current state after restoring: {'_iteration': 200, '_timesteps_total': None, '_time_total': 7.776991128921509, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.25]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.28]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.28]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.28]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.29]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.22]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.23]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.26]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.22]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.25]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.25]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.29]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.29]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.23]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.26]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.23]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.2] 0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.31]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.27]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.24]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=2.24]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.24]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.27]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.17]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.22]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.32]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.17]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.21]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.22]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.24]0:   0%|          | 2/1000 [00:00<06:03,  2.75it/s, Loss/Training=2.23]0:   0%|          | 2/1000 [00:01<06:03,  2.75it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.23]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.23]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.22]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.25]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.24]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.26]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.19]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.2] 0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.22]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.25]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.25]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.23]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.24]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.19]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.26]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.17]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.14]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.2] 0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.18]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.17]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=2.23]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.23]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.2] 0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.21]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.21]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.2] 0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.24]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.24]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.22]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.24]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.28]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=2.21]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.21]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.17]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.24]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.2] 0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.23]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.23]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.22]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.2] 0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.24]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.15]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=2.19]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.19]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.13]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.14]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.15]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.19]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.16]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.17]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.2] 0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.16]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.17]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=2.22]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.22]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.19]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.2] 0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.18]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.14]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.15]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.09]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.14]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.16]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.2] 0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=2.15]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.15]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.16]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.04]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.13]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.15]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.13]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.13]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.17]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.19]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.16]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=2.12]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp80876c
[INFO 2025-01-27 15:40:03,338] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp80876c
Current state after restoring: {'_iteration': 300, '_timesteps_total': None, '_time_total': 11.688225746154785, '_episodes_total': None}
[INFO 2025-01-27 15:40:03,338] trainable.py: 913  Current state after restoring: {'_iteration': 300, '_timesteps_total': None, '_time_total': 11.688225746154785, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.17]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.12]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.09]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.12]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.1] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.11]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.09]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.09]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.04]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=2.08]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.08]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.09]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.11]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.14]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.09]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.07]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.05]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.08]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.08]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.02]0:   0%|          | 1/1000 [00:00<07:07,  2.33it/s, Loss/Training=2.07]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.07]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.07]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.15]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.05]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.02]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.05]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.06]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.04]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.07]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=2.06]0:   0%|          | 2/1000 [00:01<06:04,  2.74it/s, Loss/Training=2.04]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.04]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=1.98]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=1.98]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.08]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.01]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.03]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.03]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=1.98]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=1.99]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=2.04]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=1.89]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.89]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.01]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.95]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2.01]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=2]   0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.99]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.88]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.96]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.91]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.94]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=1.91]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.91]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.86]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.86]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.91]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.86]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.76]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.81]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.72]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.84]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.98]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.78]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.78]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.76]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.8] 0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.86]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.77]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.8] 0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.8]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.79]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.69]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.76]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=1.73]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.73]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.81]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.91]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.7] 0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.68]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.66]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.74]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.73]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.78]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.67]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=1.67]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.67]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.64]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.53]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.65]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.69]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.44]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.6] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.52]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.62]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.57]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=1.52]0:   1%|          | 9/1000 [00:02<05:19,  3.10it/s, Loss/Training=1.52]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.46]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.5] 0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.67]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.45]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.47]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.37]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.57]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.27]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.25]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=1.31]0:   1%|          | 9/1000 [00:03<06:24,  2.58it/s, Loss/Training=1.31]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpfc3175
[INFO 2025-01-27 15:40:32,124] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpfc3175
Current state after restoring: {'_iteration': 400, '_timesteps_total': None, '_time_total': 15.572181940078735, '_episodes_total': None}
[INFO 2025-01-27 15:40:32,124] trainable.py: 913  Current state after restoring: {'_iteration': 400, '_timesteps_total': None, '_time_total': 15.572181940078735, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.32]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.39]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.34]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.16]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.29]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.45]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.31]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.33]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.26]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=1.33]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.33]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.41]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.28]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.09]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.13]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.13]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.12]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.22]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.21]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.08]0:   0%|          | 1/1000 [00:00<07:17,  2.28it/s, Loss/Training=1.19]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.19]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.36]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.26]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.17]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.14]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.06]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.05]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.29]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=1.04]0:   0%|          | 2/1000 [00:01<06:10,  2.69it/s, Loss/Training=1.09]0:   0%|          | 2/1000 [00:01<06:10,  2.69it/s, Loss/Training=0.947]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.947]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=1.03] 0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.958]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.974]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=1.07] 0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=1]   0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.987]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=1.06] 0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.912]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.73] 0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.742]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.742]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=1.05] 0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.838]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.863]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.717]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.859]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.894]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.975]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.826]0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.74] 0:   0%|          | 4/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.838]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.838]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.81] 0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.07]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.664]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.814]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.991]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.793]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.796]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.94] 0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.886]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=1.16] 0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=1.16]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.919]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.638]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.719]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.733]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.838]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.794]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.902]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.823]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.747]0:   1%|          | 6/1000 [00:02<05:25,  3.06it/s, Loss/Training=0.585]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.585]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.864]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.682]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.822]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.58] 0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.725]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.658]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.769]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.655]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.623]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.924]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.924]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.751]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.585]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.787]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.715]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.549]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.494]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.546]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.45] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.618]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.676]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.676]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.617]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.758]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.634]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.509]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.54] 0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.718]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.689]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.517]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.701]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.333]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp0dce2e
[INFO 2025-01-27 15:40:57,214] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp0dce2e
Current state after restoring: {'_iteration': 500, '_timesteps_total': None, '_time_total': 19.481292724609375, '_episodes_total': None}
[INFO 2025-01-27 15:40:57,214] trainable.py: 913  Current state after restoring: {'_iteration': 500, '_timesteps_total': None, '_time_total': 19.481292724609375, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.729]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.609]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.78] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.487]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.346]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.585]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.483]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.449]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.452]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.274]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.274]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.487]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.858]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.439]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.545]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.483]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.326]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.522]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.433]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.477]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.559]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.559]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.57] 0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.547]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.53] 0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.39]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.507]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.774]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.778]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.583]0:   0%|          | 2/1000 [00:00<06:00,  2.77it/s, Loss/Training=0.818]0:   0%|          | 2/1000 [00:01<06:00,  2.77it/s, Loss/Training=0.542]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.542]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.474]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.682]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.53] 0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.499]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.538]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.534]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.471]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.569]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.501]0:   0%|          | 3/1000 [00:01<05:44,  2.90it/s, Loss/Training=0.457]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.457]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.501]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.584]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.534]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.597]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.554]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.48] 0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.435]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.513]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.68] 0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.404]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.404]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.598]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.407]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.491]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.573]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.558]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.531]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.513]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.603]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.397]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.658]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.658]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.549]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.684]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.608]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.447]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.535]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.583]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.441]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.483]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.602]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.698]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.698]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.527]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.509]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.456]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.538]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.64] 0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.421]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.48] 0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.452]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.511]0:   1%|          | 7/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.447]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.447]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.54] 0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.642]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.349]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.489]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.473]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.799]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.757]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.642]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.419]0:   1%|          | 8/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.476]0:   1%|          | 9/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.476]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.583]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.468]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.565]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.428]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.361]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.632]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.39] 0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.47]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.664]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.567]0:   1%|          | 9/1000 [00:03<06:13,  2.65it/s, Loss/Training=0.567]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpf2d06b
[INFO 2025-01-27 15:41:24,979] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpf2d06b
Current state after restoring: {'_iteration': 600, '_timesteps_total': None, '_time_total': 23.37039828300476, '_episodes_total': None}
[INFO 2025-01-27 15:41:24,980] trainable.py: 913  Current state after restoring: {'_iteration': 600, '_timesteps_total': None, '_time_total': 23.37039828300476, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.472]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.661]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.439]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.508]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.389]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.456]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.256]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.334]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.558]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.537]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.537]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.288]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.526]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.482]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.462]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.627]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.501]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.475]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.363]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.417]0:   0%|          | 1/1000 [00:00<07:02,  2.36it/s, Loss/Training=0.364]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.364]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.48] 0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.359]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.296]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.31] 0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.517]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.418]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.717]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.656]0:   0%|          | 2/1000 [00:00<06:02,  2.75it/s, Loss/Training=0.334]0:   0%|          | 2/1000 [00:01<06:02,  2.75it/s, Loss/Training=0.448]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.448]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.482]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.391]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.359]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.377]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.388]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.472]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.316]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.441]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.711]0:   0%|          | 3/1000 [00:01<05:43,  2.90it/s, Loss/Training=0.612]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.612]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.56] 0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.401]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.417]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.518]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.718]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.447]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.362]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.525]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.278]0:   0%|          | 4/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.49] 0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.49]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.369]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.535]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.359]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.236]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.361]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.38] 0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.33]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.367]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.351]0:   0%|          | 5/1000 [00:01<05:28,  3.03it/s, Loss/Training=0.301]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.301]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.358]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.421]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.525]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.407]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.406]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.414]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.439]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.361]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.656]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.399]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.399]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.643]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.587]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.491]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.384]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.484]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.381]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.465]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.468]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.448]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.322]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.322]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.447]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.318]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.317]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.549]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.441]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.726]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.516]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.28] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.863]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.47] 0:   1%|          | 9/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.47]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.559]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.304]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.395]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.424]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.608]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.681]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.358]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.461]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.558]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.694]0:   1%|          | 9/1000 [00:03<06:43,  2.46it/s, Loss/Training=0.694]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp107995
[INFO 2025-01-27 15:41:51,821] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp107995
Current state after restoring: {'_iteration': 700, '_timesteps_total': None, '_time_total': 27.260974884033203, '_episodes_total': None}
[INFO 2025-01-27 15:41:51,821] trainable.py: 913  Current state after restoring: {'_iteration': 700, '_timesteps_total': None, '_time_total': 27.260974884033203, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.426]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.497]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.38] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.522]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.404]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.471]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.444]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.334]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.186]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.366]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.366]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.28] 0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.343]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.427]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.33] 0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.691]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.36] 0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.453]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.79] 0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.372]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.47] 0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.47]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.329]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.393]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.311]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.354]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.358]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.54] 0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.418]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.487]0:   0%|          | 2/1000 [00:01<06:08,  2.71it/s, Loss/Training=0.2]  0:   0%|          | 2/1000 [00:01<06:08,  2.71it/s, Loss/Training=0.512]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.512]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.33] 0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.393]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.688]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.608]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.218]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.76] 0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.341]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.499]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.338]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.465]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.465]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.557]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.418]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.4]  0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.63]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.392]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.469]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.281]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.467]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.317]0:   0%|          | 4/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.381]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.381]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.495]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.306]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.387]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.463]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.296]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.496]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.313]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.531]0:   0%|          | 5/1000 [00:02<05:40,  2.92it/s, Loss/Training=0.378]0:   0%|          | 5/1000 [00:02<05:40,  2.92it/s, Loss/Training=0.412]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.412]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.209]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.377]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.396]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.245]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.498]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.646]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.256]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.31] 0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.493]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.345]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.345]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.359]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.375]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.456]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.242]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.446]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.267]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.454]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.425]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.436]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.217]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.217]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.333]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.446]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.51] 0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.509]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.435]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.327]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.32] 0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.572]0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.39] 0:   1%|          | 8/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.501]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.501]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.311]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.47] 0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.34]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.391]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.462]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.525]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.321]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.33] 0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.403]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.355]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpa1a057
[INFO 2025-01-27 15:42:17,325] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpa1a057
Current state after restoring: {'_iteration': 700, '_timesteps_total': None, '_time_total': 27.43070149421692, '_episodes_total': None}
[INFO 2025-01-27 15:42:17,326] trainable.py: 913  Current state after restoring: {'_iteration': 700, '_timesteps_total': None, '_time_total': 27.43070149421692, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.489]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.463]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.556]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.554]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.727]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.489]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.326]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.349]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.484]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.503]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.503]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.381]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.535]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.538]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.512]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.537]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.379]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.455]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.425]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.436]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.409]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.409]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.607]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.364]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.514]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.544]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.581]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.412]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.416]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.446]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.728]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.447]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.447]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.5]  0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.325]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.517]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.366]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.426]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.494]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.46] 0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.694]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.561]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.495]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.495]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.458]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.548]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.428]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.55] 0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.668]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.477]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.669]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.567]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.424]0:   0%|          | 4/1000 [00:01<05:40,  2.93it/s, Loss/Training=0.242]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.242]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.392]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.397]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.443]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.301]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.432]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.499]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.589]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.406]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.477]0:   0%|          | 5/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.309]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.309]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.321]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.684]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.403]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.42] 0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.404]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.425]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.244]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.456]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.434]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.417]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.417]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.365]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.355]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.383]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.498]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.405]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.369]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.34] 0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.34]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.472]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.178]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.178]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.484]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.307]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.429]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.48] 0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.411]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.366]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.572]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.548]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.721]0:   1%|          | 8/1000 [00:02<05:24,  3.05it/s, Loss/Training=0.612]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.612]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.292]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.497]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.463]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.609]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.414]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.511]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.454]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.18] 0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.497]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.461]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpaf8d88
[INFO 2025-01-27 15:42:46,050] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpaf8d88
Current state after restoring: {'_iteration': 800, '_timesteps_total': None, '_time_total': 31.414628505706787, '_episodes_total': None}
[INFO 2025-01-27 15:42:46,050] trainable.py: 913  Current state after restoring: {'_iteration': 800, '_timesteps_total': None, '_time_total': 31.414628505706787, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.293]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.424]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.332]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.528]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.355]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.564]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.321]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.5]  0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.709]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.498]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.498]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.304]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.385]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.348]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.495]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.373]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.469]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.52] 0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.319]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.603]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.697]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.697]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.507]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.428]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.327]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.545]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.325]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.462]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.307]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.558]0:   0%|          | 2/1000 [00:01<06:08,  2.71it/s, Loss/Training=0.526]0:   0%|          | 2/1000 [00:01<06:08,  2.71it/s, Loss/Training=0.615]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.615]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.577]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.363]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.516]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.324]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.466]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.283]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.314]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.487]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.381]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.46] 0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.46]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.449]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.459]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.308]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.43] 0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.288]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.821]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.638]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.549]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.387]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.405]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.405]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.346]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.474]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.604]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.381]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.546]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.306]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.299]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.415]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.433]0:   0%|          | 5/1000 [00:01<05:31,  3.01it/s, Loss/Training=0.411]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.411]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.494]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.341]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.653]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.297]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.359]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.541]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.589]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.343]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.51] 0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.367]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.367]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.412]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.476]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.41] 0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.174]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.451]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.312]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.482]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.43] 0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.302]0:   1%|          | 7/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.432]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.432]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.263]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.633]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.407]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.59] 0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.448]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.354]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.477]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.359]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.324]0:   1%|          | 8/1000 [00:02<05:22,  3.07it/s, Loss/Training=0.48] 0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.48]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.364]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.416]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.385]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.497]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.46] 0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.446]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.476]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.433]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.424]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.284]0:   1%|          | 9/1000 [00:03<06:26,  2.56it/s, Loss/Training=0.284]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp96b903
[INFO 2025-01-27 15:43:12,638] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp96b903
Current state after restoring: {'_iteration': 900, '_timesteps_total': None, '_time_total': 35.33958101272583, '_episodes_total': None}
[INFO 2025-01-27 15:43:12,639] trainable.py: 913  Current state after restoring: {'_iteration': 900, '_timesteps_total': None, '_time_total': 35.33958101272583, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.473]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.493]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.281]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.409]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.303]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.395]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.302]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.408]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.44] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.341]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.341]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.327]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.336]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.491]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.351]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.492]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.457]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.44] 0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.413]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.318]0:   0%|          | 1/1000 [00:00<07:07,  2.34it/s, Loss/Training=0.657]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.657]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.513]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.476]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.363]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.586]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.606]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.55] 0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.459]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.375]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.354]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.52] 0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.52]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.236]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.421]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.46] 0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.577]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.617]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.41] 0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.443]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.297]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.309]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.357]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.357]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.434]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.445]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.516]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.269]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.37] 0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.533]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.343]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.449]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.305]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.42] 0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.42]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.505]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.594]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.374]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.638]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.564]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.349]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.55] 0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.331]0:   0%|          | 5/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.397]0:   0%|          | 5/1000 [00:02<05:32,  3.00it/s, Loss/Training=0.461]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.461]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.254]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.373]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.338]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.374]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.509]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.555]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.634]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.439]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.314]0:   1%|          | 6/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.405]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.405]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.482]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.536]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.386]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.288]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.48] 0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.461]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.431]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.492]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.34] 0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.525]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.525]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.411]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.429]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.727]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.33] 0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.726]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.645]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.638]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.264]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.499]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.334]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.334]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.386]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.372]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.397]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.416]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.381]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.358]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.373]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.462]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.307]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.487]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp00f758
[INFO 2025-01-27 15:43:40,075] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp00f758
Current state after restoring: {'_iteration': 1000, '_timesteps_total': None, '_time_total': 39.25189995765686, '_episodes_total': None}
[INFO 2025-01-27 15:43:40,075] trainable.py: 913  Current state after restoring: {'_iteration': 1000, '_timesteps_total': None, '_time_total': 39.25189995765686, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.451]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.353]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.443]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.272]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.469]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.512]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.472]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.363]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.313]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.509]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.509]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.56] 0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.434]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.424]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.515]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.623]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.412]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.282]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.347]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.514]0:   0%|          | 1/1000 [00:00<07:01,  2.37it/s, Loss/Training=0.495]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.495]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.385]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.394]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.45] 0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.452]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.317]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.246]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.706]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.403]0:   0%|          | 2/1000 [00:01<06:12,  2.68it/s, Loss/Training=0.295]0:   0%|          | 2/1000 [00:01<06:12,  2.68it/s, Loss/Training=0.469]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.469]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.609]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.419]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.401]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.416]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.358]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.345]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.282]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.557]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.379]0:   0%|          | 3/1000 [00:01<05:48,  2.86it/s, Loss/Training=0.476]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.476]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.288]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.402]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.216]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.627]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.296]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.549]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.526]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.294]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.472]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.339]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.339]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.688]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.413]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.309]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.332]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.506]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.359]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.474]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.315]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.355]0:   0%|          | 5/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.534]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.534]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.216]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.437]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.491]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.556]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.381]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.376]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.309]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.487]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.476]0:   1%|          | 6/1000 [00:02<05:27,  3.04it/s, Loss/Training=0.272]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.272]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.474]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.517]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.485]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.348]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.306]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.473]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.366]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.404]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.398]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.602]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.602]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.423]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.456]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.497]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.731]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.4]  0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.365]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.442]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.295]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.539]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.446]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.446]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.462]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.483]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.616]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.524]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.314]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.484]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.505]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.371]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.494]0:   1%|          | 9/1000 [00:03<05:20,  3.09it/s, Loss/Training=0.622]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp892f1d
[INFO 2025-01-27 15:44:07,250] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp892f1d
Current state after restoring: {'_iteration': 1100, '_timesteps_total': None, '_time_total': 43.17313051223755, '_episodes_total': None}
[INFO 2025-01-27 15:44:07,251] trainable.py: 913  Current state after restoring: {'_iteration': 1100, '_timesteps_total': None, '_time_total': 43.17313051223755, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.533]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.351]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.446]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.408]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.382]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.443]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.644]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.658]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.414]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.499]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.499]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.47] 0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.287]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.3]  0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.333]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.359]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.384]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.536]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.263]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.462]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.586]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.586]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.459]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.319]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.336]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.338]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.212]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.223]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.505]0:   0%|          | 2/1000 [00:00<06:06,  2.72it/s, Loss/Training=0.348]0:   0%|          | 2/1000 [00:01<06:06,  2.72it/s, Loss/Training=0.228]0:   0%|          | 2/1000 [00:01<06:06,  2.72it/s, Loss/Training=0.359]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.359]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.371]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.328]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.405]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.251]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.52] 0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.504]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.388]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.379]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.367]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.309]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.309]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.395]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.32] 0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.507]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.355]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.381]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.488]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.278]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.346]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.534]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.432]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.432]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.302]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.356]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.299]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.474]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.314]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.395]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.407]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.215]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.366]0:   0%|          | 5/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.593]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.593]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.34] 0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.482]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.387]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.284]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.377]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.428]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.494]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.562]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.459]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.318]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.318]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.184]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.286]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.379]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.307]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.351]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.543]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.391]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.431]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.394]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.432]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.432]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.335]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.36] 0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.291]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.382]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.427]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.507]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.318]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.573]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.462]0:   1%|          | 8/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.256]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.256]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.449]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.497]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.451]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.4]  0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.442]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.481]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.356]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.329]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.402]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.41] 0:   1%|          | 9/1000 [00:03<06:16,  2.63it/s, Loss/Training=0.41]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp7f9d43
[INFO 2025-01-27 15:44:33,279] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp7f9d43
Current state after restoring: {'_iteration': 1200, '_timesteps_total': None, '_time_total': 47.08817744255066, '_episodes_total': None}
[INFO 2025-01-27 15:44:33,279] trainable.py: 913  Current state after restoring: {'_iteration': 1200, '_timesteps_total': None, '_time_total': 47.08817744255066, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.443]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.412]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.265]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.445]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.151]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.362]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.536]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.408]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.482]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.471]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.471]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.539]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.431]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.337]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.559]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.192]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.484]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.414]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.352]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.448]0:   0%|          | 1/1000 [00:00<07:16,  2.29it/s, Loss/Training=0.402]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.402]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.445]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.364]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.355]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.368]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.343]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.547]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.417]0:   0%|          | 2/1000 [00:00<06:08,  2.71it/s, Loss/Training=0.565]0:   0%|          | 2/1000 [00:01<06:08,  2.71it/s, Loss/Training=0.576]0:   0%|          | 2/1000 [00:01<06:08,  2.71it/s, Loss/Training=0.453]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.453]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.364]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.498]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.441]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.192]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.398]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.381]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.535]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.347]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.477]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.562]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.562]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.579]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.389]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.408]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.409]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.548]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.434]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.415]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.483]0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.53] 0:   0%|          | 4/1000 [00:01<05:34,  2.98it/s, Loss/Training=0.444]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.444]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.528]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.563]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.326]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.344]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.5]  0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.242]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.255]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.61] 0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.476]0:   0%|          | 5/1000 [00:01<05:29,  3.02it/s, Loss/Training=0.499]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.499]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.332]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.529]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.399]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.465]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.319]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.43] 0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.362]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.285]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.437]0:   1%|          | 6/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.387]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.387]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.412]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.391]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.376]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.317]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.418]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.321]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.284]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.268]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.357]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.439]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.439]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.325]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.376]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.385]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.518]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.269]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.397]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.503]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.174]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.437]0:   1%|          | 8/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.265]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.265]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.773]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.516]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.328]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.336]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.548]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.326]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.448]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.603]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.245]0:   1%|          | 9/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.299]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp5ee5a0
[INFO 2025-01-27 15:45:02,183] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp5ee5a0
Current state after restoring: {'_iteration': 1200, '_timesteps_total': None, '_time_total': 47.11950373649597, '_episodes_total': None}
[INFO 2025-01-27 15:45:02,184] trainable.py: 913  Current state after restoring: {'_iteration': 1200, '_timesteps_total': None, '_time_total': 47.11950373649597, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.465]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.437]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.45] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.563]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.32] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.446]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.186]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.44] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.529]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.296]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.296]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.398]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.459]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.435]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.479]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.367]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.463]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.315]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.28] 0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.381]0:   0%|          | 1/1000 [00:00<07:26,  2.24it/s, Loss/Training=0.304]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.304]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.435]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.367]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.229]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.364]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.642]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.31] 0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.521]0:   0%|          | 2/1000 [00:00<06:16,  2.65it/s, Loss/Training=0.543]0:   0%|          | 2/1000 [00:01<06:16,  2.65it/s, Loss/Training=0.346]0:   0%|          | 2/1000 [00:01<06:16,  2.65it/s, Loss/Training=0.374]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.374]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.552]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.448]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.42] 0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.337]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.429]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.36] 0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.347]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.493]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.489]0:   0%|          | 3/1000 [00:01<05:57,  2.78it/s, Loss/Training=0.347]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.347]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.393]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.477]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.577]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.443]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.527]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.488]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.678]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.384]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.509]0:   0%|          | 4/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.561]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.561]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.38] 0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.371]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.454]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.447]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.419]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.481]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.662]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.324]0:   0%|          | 5/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.547]0:   0%|          | 5/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.256]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.256]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.204]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.436]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.544]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.405]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.297]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.456]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.281]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.333]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.424]0:   1%|          | 6/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.69] 0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.69]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.349]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.449]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.397]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.387]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.409]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.341]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.377]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.548]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.416]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.453]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.453]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.277]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.251]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.547]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.361]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.706]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.324]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.237]0:   1%|          | 8/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.554]0:   1%|          | 8/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.37] 0:   1%|          | 8/1000 [00:03<05:27,  3.03it/s, Loss/Training=0.433]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.433]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.37] 0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.527]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.483]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.505]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.437]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.249]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.33] 0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.387]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.416]0:   1%|          | 9/1000 [00:03<05:28,  3.01it/s, Loss/Training=0.67] 0:   1%|          | 9/1000 [00:03<06:26,  2.56it/s, Loss/Training=0.67]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpdc9328
[INFO 2025-01-27 15:45:28,160] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpdc9328
Current state after restoring: {'_iteration': 1300, '_timesteps_total': None, '_time_total': 51.24193000793457, '_episodes_total': None}
[INFO 2025-01-27 15:45:28,160] trainable.py: 913  Current state after restoring: {'_iteration': 1300, '_timesteps_total': None, '_time_total': 51.24193000793457, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.511]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.382]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.158]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.391]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.463]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.282]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.525]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.427]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.278]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.325]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.325]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.448]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.45] 0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.357]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.438]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.574]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.386]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.56] 0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.535]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.758]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.347]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.347]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.337]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.551]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.334]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.58] 0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.337]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.247]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.429]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.418]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.454]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.366]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.366]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.424]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.511]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.287]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.481]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.367]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.396]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.348]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.272]0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.19] 0:   0%|          | 3/1000 [00:01<05:46,  2.88it/s, Loss/Training=0.544]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.544]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.459]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.388]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.339]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.298]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.419]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.249]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.413]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.304]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.482]0:   0%|          | 4/1000 [00:01<05:35,  2.97it/s, Loss/Training=0.382]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.382]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.49] 0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.276]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.293]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.243]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.459]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.553]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.382]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.246]0:   0%|          | 5/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.435]0:   0%|          | 5/1000 [00:02<05:38,  2.94it/s, Loss/Training=0.548]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.548]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.466]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.373]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.507]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.307]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.405]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.389]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.473]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.497]0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.32] 0:   1%|          | 6/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.29]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.29]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.737]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.474]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.274]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.454]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.59] 0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.548]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.416]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.561]0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.46] 0:   1%|          | 7/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.252]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.252]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.242]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.423]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.398]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.365]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.304]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.657]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.47] 0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.297]0:   1%|          | 8/1000 [00:02<05:27,  3.02it/s, Loss/Training=0.52] 0:   1%|          | 8/1000 [00:03<05:27,  3.02it/s, Loss/Training=0.327]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.327]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.551]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.298]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.344]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.294]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.419]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.599]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.626]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.337]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.461]0:   1%|          | 9/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.316]0:   1%|          | 9/1000 [00:03<06:21,  2.60it/s, Loss/Training=0.316]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp76adfb
[INFO 2025-01-27 15:45:54,673] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp76adfb
Current state after restoring: {'_iteration': 1400, '_timesteps_total': None, '_time_total': 55.15346336364746, '_episodes_total': None}
[INFO 2025-01-27 15:45:54,674] trainable.py: 913  Current state after restoring: {'_iteration': 1400, '_timesteps_total': None, '_time_total': 55.15346336364746, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.176]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.246]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.386]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.574]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.333]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.277]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.417]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.446]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.224]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.494]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.494]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.288]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.421]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.258]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.351]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.461]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.455]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.451]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.354]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.654]0:   0%|          | 1/1000 [00:00<08:28,  1.97it/s, Loss/Training=0.441]0:   0%|          | 2/1000 [00:00<06:56,  2.40it/s, Loss/Training=0.441]0:   0%|          | 2/1000 [00:00<06:56,  2.40it/s, Loss/Training=0.499]0:   0%|          | 2/1000 [00:00<06:56,  2.40it/s, Loss/Training=0.3]  0:   0%|          | 2/1000 [00:00<06:56,  2.40it/s, Loss/Training=0.419]0:   0%|          | 2/1000 [00:00<06:56,  2.40it/s, Loss/Training=0.331]0:   0%|          | 2/1000 [00:00<06:56,  2.40it/s, Loss/Training=0.594]0:   0%|          | 2/1000 [00:01<06:56,  2.40it/s, Loss/Training=0.439]0:   0%|          | 2/1000 [00:01<06:56,  2.40it/s, Loss/Training=0.423]0:   0%|          | 2/1000 [00:01<06:56,  2.40it/s, Loss/Training=0.272]0:   0%|          | 2/1000 [00:01<06:56,  2.40it/s, Loss/Training=0.116]0:   0%|          | 2/1000 [00:01<06:56,  2.40it/s, Loss/Training=0.311]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.311]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.385]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.348]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.36] 0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.718]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.344]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.58] 0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.333]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.405]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.289]0:   0%|          | 3/1000 [00:01<06:12,  2.67it/s, Loss/Training=0.341]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.341]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.416]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.167]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.344]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.376]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.409]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.375]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.447]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.368]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.465]0:   0%|          | 4/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.543]0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.543]0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.343]0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.408]0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.577]0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.35] 0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.355]0:   0%|          | 5/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.358]0:   0%|          | 5/1000 [00:02<05:41,  2.92it/s, Loss/Training=0.382]0:   0%|          | 5/1000 [00:02<05:41,  2.92it/s, Loss/Training=0.503]0:   0%|          | 5/1000 [00:02<05:41,  2.92it/s, Loss/Training=0.346]0:   0%|          | 5/1000 [00:02<05:41,  2.92it/s, Loss/Training=0.191]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.191]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.441]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.457]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.248]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.495]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.506]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.272]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.361]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.507]0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.35] 0:   1%|          | 6/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.49]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.49]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.352]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.365]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.328]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.492]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.442]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.46] 0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.452]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.422]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.383]0:   1%|          | 7/1000 [00:02<05:30,  3.01it/s, Loss/Training=0.393]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.393]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.388]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.506]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.333]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.347]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.357]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.546]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.548]0:   1%|          | 8/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.517]0:   1%|          | 8/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.391]0:   1%|          | 8/1000 [00:03<05:26,  3.04it/s, Loss/Training=0.365]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.365]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.475]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.364]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.52] 0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.357]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.397]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.77] 0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.383]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.322]0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.4]  0:   1%|          | 9/1000 [00:03<05:22,  3.07it/s, Loss/Training=0.336]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpa140d0
[INFO 2025-01-27 15:46:22,381] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpa140d0
Current state after restoring: {'_iteration': 1500, '_timesteps_total': None, '_time_total': 59.12827491760254, '_episodes_total': None}
[INFO 2025-01-27 15:46:22,381] trainable.py: 913  Current state after restoring: {'_iteration': 1500, '_timesteps_total': None, '_time_total': 59.12827491760254, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.502]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.386]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.422]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.304]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.376]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.449]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.404]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.378]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.27] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.215]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.215]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.449]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.479]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.311]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.392]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.45] 0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.383]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.231]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.418]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.462]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.267]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.267]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.369]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.487]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.378]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.294]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.377]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.425]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.428]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.298]0:   0%|          | 2/1000 [00:00<06:03,  2.74it/s, Loss/Training=0.29] 0:   0%|          | 2/1000 [00:01<06:03,  2.74it/s, Loss/Training=0.404]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.404]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.444]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.267]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.488]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.404]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.261]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.443]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.497]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.249]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.563]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.281]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.281]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.267]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.323]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.232]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.307]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.317]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.312]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.36] 0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.224]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.406]0:   0%|          | 4/1000 [00:01<05:33,  2.99it/s, Loss/Training=0.538]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.538]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.288]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.369]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.37] 0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.498]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.218]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.265]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.416]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.535]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.279]0:   0%|          | 5/1000 [00:01<05:27,  3.03it/s, Loss/Training=0.598]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.598]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.366]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.61] 0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.393]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.332]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.432]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.552]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.62] 0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.348]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.208]0:   1%|          | 6/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.343]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.343]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.305]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.459]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.494]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.484]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.333]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.239]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.464]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.222]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.467]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.399]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.399]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.494]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.402]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.267]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.19] 0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.459]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.45] 0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.405]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.365]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.449]0:   1%|          | 8/1000 [00:02<05:21,  3.08it/s, Loss/Training=0.274]0:   1%|          | 9/1000 [00:02<05:19,  3.10it/s, Loss/Training=0.274]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.363]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.294]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.263]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.358]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.418]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.5]  0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.468]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.484]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.546]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.256]0:   1%|          | 9/1000 [00:03<06:23,  2.59it/s, Loss/Training=0.256]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpe3f7bd
[INFO 2025-01-27 15:46:47,365] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpe3f7bd
Current state after restoring: {'_iteration': 1600, '_timesteps_total': None, '_time_total': 63.01052641868591, '_episodes_total': None}
[INFO 2025-01-27 15:46:47,365] trainable.py: 913  Current state after restoring: {'_iteration': 1600, '_timesteps_total': None, '_time_total': 63.01052641868591, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.442]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.411]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.215]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.176]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.291]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.29] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.449]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.431]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.392]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.261]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.261]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.386]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.396]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.285]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.311]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.469]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.342]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.28] 0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.371]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.321]0:   0%|          | 1/1000 [00:00<07:05,  2.35it/s, Loss/Training=0.257]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.257]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.531]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.338]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.49] 0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.355]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.309]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.573]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.334]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.418]0:   0%|          | 2/1000 [00:00<06:04,  2.74it/s, Loss/Training=0.488]0:   0%|          | 2/1000 [00:01<06:04,  2.74it/s, Loss/Training=0.548]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.548]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.361]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.253]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.256]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.349]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.331]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.385]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.597]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.324]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.477]0:   0%|          | 3/1000 [00:01<05:41,  2.92it/s, Loss/Training=0.349]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.349]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.356]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.29] 0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.33]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.446]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.416]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.267]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.305]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.46] 0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.504]0:   0%|          | 4/1000 [00:01<05:32,  3.00it/s, Loss/Training=0.322]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.322]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.492]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.225]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.533]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.224]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.478]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.268]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.306]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.273]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.461]0:   0%|          | 5/1000 [00:01<05:31,  3.00it/s, Loss/Training=0.368]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.368]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.301]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.377]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.342]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.439]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.301]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.336]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.588]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.291]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.455]0:   1%|          | 6/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.501]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.501]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.412]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.463]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.3]  0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.418]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.35] 0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.452]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.347]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.587]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.608]0:   1%|          | 7/1000 [00:02<05:21,  3.09it/s, Loss/Training=0.455]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.455]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.427]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.396]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.408]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.369]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.325]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.586]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.278]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.24] 0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.434]0:   1%|          | 8/1000 [00:02<05:22,  3.08it/s, Loss/Training=0.448]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.448]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.411]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.305]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.337]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.377]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.337]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.435]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.463]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.253]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.549]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.338]0:   1%|          | 9/1000 [00:03<06:15,  2.64it/s, Loss/Training=0.338]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpb6ccb4
[INFO 2025-01-27 15:47:15,275] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpb6ccb4
Current state after restoring: {'_iteration': 1700, '_timesteps_total': None, '_time_total': 66.95700025558472, '_episodes_total': None}
[INFO 2025-01-27 15:47:15,275] trainable.py: 913  Current state after restoring: {'_iteration': 1700, '_timesteps_total': None, '_time_total': 66.95700025558472, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.287]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.429]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.279]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.404]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.377]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.463]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.23] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.419]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.417]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.293]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.293]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.492]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.431]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.212]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.306]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.373]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.373]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.449]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.361]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.366]0:   0%|          | 1/1000 [00:00<07:08,  2.33it/s, Loss/Training=0.214]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.214]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.356]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.464]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.419]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.29] 0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.546]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.354]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.42] 0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.287]0:   0%|          | 2/1000 [00:00<06:05,  2.73it/s, Loss/Training=0.446]0:   0%|          | 2/1000 [00:01<06:05,  2.73it/s, Loss/Training=0.209]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.209]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.286]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.542]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.387]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.407]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.387]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.449]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.438]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.294]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.285]0:   0%|          | 3/1000 [00:01<05:44,  2.89it/s, Loss/Training=0.425]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.425]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.16] 0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.341]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.427]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.285]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.393]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.344]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.343]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.399]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.358]0:   0%|          | 4/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.328]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.328]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.421]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.8]  0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.351]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.301]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.41] 0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.406]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.7]  0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.405]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.509]0:   0%|          | 5/1000 [00:01<05:30,  3.01it/s, Loss/Training=0.348]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.348]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.442]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.256]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.494]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.436]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.437]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.308]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.197]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.211]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.393]0:   1%|          | 6/1000 [00:02<05:26,  3.05it/s, Loss/Training=0.266]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.266]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.304]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.329]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.42] 0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.685]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.299]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.496]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.429]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.248]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.367]0:   1%|          | 7/1000 [00:02<05:23,  3.07it/s, Loss/Training=0.421]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.421]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.287]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.319]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.403]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.364]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.26] 0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.306]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.529]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.185]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.401]0:   1%|          | 8/1000 [00:02<05:23,  3.06it/s, Loss/Training=0.346]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.346]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.191]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.443]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.446]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.374]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.414]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.47] 0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.354]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.41] 0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.55]0:   1%|          | 9/1000 [00:03<05:21,  3.08it/s, Loss/Training=0.401]0:   1%|          | 9/1000 [00:03<06:25,  2.57it/s, Loss/Training=0.401]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpc9557f
[INFO 2025-01-27 15:47:40,904] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpc9557f
Current state after restoring: {'_iteration': 1800, '_timesteps_total': None, '_time_total': 70.86300325393677, '_episodes_total': None}
[INFO 2025-01-27 15:47:40,904] trainable.py: 913  Current state after restoring: {'_iteration': 1800, '_timesteps_total': None, '_time_total': 70.86300325393677, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.58]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.341]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.223]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.409]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.389]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.252]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.364]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.239]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.356]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.344]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.344]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.239]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.338]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.351]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.414]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.35] 0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.338]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.497]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.3]  0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.309]0:   0%|          | 1/1000 [00:00<07:14,  2.30it/s, Loss/Training=0.324]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.324]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.326]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.479]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.252]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.259]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.482]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.367]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.295]0:   0%|          | 2/1000 [00:00<06:09,  2.70it/s, Loss/Training=0.511]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.559]0:   0%|          | 2/1000 [00:01<06:09,  2.70it/s, Loss/Training=0.334]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.334]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.412]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.493]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.362]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.427]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.315]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.31] 0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.37]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.37]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.336]0:   0%|          | 3/1000 [00:01<05:47,  2.87it/s, Loss/Training=0.405]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.405]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.386]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.478]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.509]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.201]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.746]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.537]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.442]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.24] 0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.396]0:   0%|          | 4/1000 [00:01<05:37,  2.95it/s, Loss/Training=0.314]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.314]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.282]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.595]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.32] 0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.526]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.285]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.472]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.234]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.398]0:   0%|          | 5/1000 [00:01<05:35,  2.96it/s, Loss/Training=0.334]0:   0%|          | 5/1000 [00:02<05:35,  2.96it/s, Loss/Training=0.278]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.278]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.475]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.264]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.438]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.368]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.336]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.343]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.325]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.463]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.363]0:   1%|          | 6/1000 [00:02<05:29,  3.02it/s, Loss/Training=0.344]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.344]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.459]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.202]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.245]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.217]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.4]  0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.387]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.161]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.551]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.305]0:   1%|          | 7/1000 [00:02<05:24,  3.06it/s, Loss/Training=0.492]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.492]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.16] 0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.321]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.247]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.266]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.358]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.335]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.564]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.367]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.424]0:   1%|          | 8/1000 [00:02<05:20,  3.09it/s, Loss/Training=0.41] 0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.41]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.408]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.435]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.358]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.347]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.316]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.505]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.334]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.514]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.247]0:   1%|          | 9/1000 [00:03<05:19,  3.10it/s, Loss/Training=0.501]0:   1%|          | 9/1000 [00:03<06:17,  2.63it/s, Loss/Training=0.501]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpab1cce
[INFO 2025-01-27 15:48:07,935] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpab1cce
Current state after restoring: {'_iteration': 1900, '_timesteps_total': None, '_time_total': 74.77284336090088, '_episodes_total': None}
[INFO 2025-01-27 15:48:07,935] trainable.py: 913  Current state after restoring: {'_iteration': 1900, '_timesteps_total': None, '_time_total': 74.77284336090088, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.405]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.719]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.403]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.381]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.73] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.326]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.282]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.281]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.453]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.262]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.262]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.393]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.445]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.171]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.43] 0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.504]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.47] 0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.32]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.59]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.335]0:   0%|          | 1/1000 [00:00<07:12,  2.31it/s, Loss/Training=0.431]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.431]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.405]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.274]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.307]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.385]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.351]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.518]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.392]0:   0%|          | 2/1000 [00:00<06:07,  2.72it/s, Loss/Training=0.437]0:   0%|          | 2/1000 [00:01<06:07,  2.72it/s, Loss/Training=0.282]0:   0%|          | 2/1000 [00:01<06:07,  2.72it/s, Loss/Training=0.465]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.465]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.411]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.271]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.551]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.304]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.18] 0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.266]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.426]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.409]0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.36] 0:   0%|          | 3/1000 [00:01<05:49,  2.86it/s, Loss/Training=0.337]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.337]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.25] 0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.309]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.493]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.361]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.406]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.473]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.287]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.222]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.474]0:   0%|          | 4/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.371]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.371]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.444]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.425]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.257]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.32] 0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.344]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.732]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.415]0:   0%|          | 5/1000 [00:01<05:39,  2.93it/s, Loss/Training=0.247]0:   0%|          | 5/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.732]0:   0%|          | 5/1000 [00:02<05:39,  2.93it/s, Loss/Training=0.295]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.295]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.476]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.363]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.315]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.347]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.332]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.268]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.343]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.339]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.38] 0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.481]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.481]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.323]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.343]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.326]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.314]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.229]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.355]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.469]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.22] 0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.287]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.371]0:   1%|          | 8/1000 [00:02<06:32,  2.53it/s, Loss/Training=0.371]0:   1%|          | 8/1000 [00:02<06:32,  2.53it/s, Loss/Training=0.202]0:   1%|          | 8/1000 [00:02<06:32,  2.53it/s, Loss/Training=0.475]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.346]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.52] 0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.303]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.471]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.526]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.401]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.354]0:   1%|          | 8/1000 [00:03<06:32,  2.53it/s, Loss/Training=0.515]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.515]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.413]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.341]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.282]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.51] 0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.404]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.416]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.485]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.415]0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.46] 0:   1%|          | 9/1000 [00:03<06:10,  2.67it/s, Loss/Training=0.425]0:   1%|          | 9/1000 [00:03<06:53,  2.40it/s, Loss/Training=0.425]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp2e907c
[INFO 2025-01-27 15:48:35,353] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp2e907c
Current state after restoring: {'_iteration': 2000, '_timesteps_total': None, '_time_total': 78.93368458747864, '_episodes_total': None}
[INFO 2025-01-27 15:48:35,353] trainable.py: 913  Current state after restoring: {'_iteration': 2000, '_timesteps_total': None, '_time_total': 78.93368458747864, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.467]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.364]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.331]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.339]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.496]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.574]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.626]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.461]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.367]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.244]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.244]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.303]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.291]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.397]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.484]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.245]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.265]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.445]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.221]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.293]0:   0%|          | 1/1000 [00:00<07:13,  2.30it/s, Loss/Training=0.58] 0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.58]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.273]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.341]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.475]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.418]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.442]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.402]0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.39] 0:   0%|          | 2/1000 [00:00<06:14,  2.66it/s, Loss/Training=0.433]0:   0%|          | 2/1000 [00:01<06:14,  2.66it/s, Loss/Training=0.307]0:   0%|          | 2/1000 [00:01<06:14,  2.66it/s, Loss/Training=0.368]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.368]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.381]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.566]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.343]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.223]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.29] 0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.514]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.429]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.451]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.415]0:   0%|          | 3/1000 [00:01<05:51,  2.83it/s, Loss/Training=0.266]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.266]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.345]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.501]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.411]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.331]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.405]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.205]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.323]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.265]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.404]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.738]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.738]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.484]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.499]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.621]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.286]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.387]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.278]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.403]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.314]0:   0%|          | 5/1000 [00:01<05:33,  2.98it/s, Loss/Training=0.585]0:   0%|          | 5/1000 [00:02<05:33,  2.98it/s, Loss/Training=0.393]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.393]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.183]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.43] 0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.174]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.283]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.293]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.341]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.209]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.333]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.255]0:   1%|          | 6/1000 [00:02<05:31,  3.00it/s, Loss/Training=0.409]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.409]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.376]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.549]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.292]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.243]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.314]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.519]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.374]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.234]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.653]0:   1%|          | 7/1000 [00:02<05:27,  3.03it/s, Loss/Training=0.306]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.306]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.432]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.543]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.261]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.315]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.215]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.395]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.274]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.177]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.426]0:   1%|          | 8/1000 [00:02<05:25,  3.05it/s, Loss/Training=0.289]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.289]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.465]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.295]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.291]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.414]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.381]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.496]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.324]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.229]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.409]0:   1%|          | 9/1000 [00:03<05:23,  3.07it/s, Loss/Training=0.362]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpb8635a
[INFO 2025-01-27 15:48:59,081] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpb8635a
Current state after restoring: {'_iteration': 2100, '_timesteps_total': None, '_time_total': 82.66174912452698, '_episodes_total': None}
[INFO 2025-01-27 15:48:59,081] trainable.py: 913  Current state after restoring: {'_iteration': 2100, '_timesteps_total': None, '_time_total': 82.66174912452698, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.397]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.373]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.452]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.429]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.366]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.374]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.407]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.353]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.569]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.417]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.417]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.448]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.4]  0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.59]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.24]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.463]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.437]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.664]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.387]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.358]0:   0%|          | 1/1000 [00:00<07:13,  2.31it/s, Loss/Training=0.409]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.409]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.525]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.233]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.398]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.33] 0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.393]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.454]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.299]0:   0%|          | 2/1000 [00:00<06:10,  2.69it/s, Loss/Training=0.303]0:   0%|          | 2/1000 [00:01<06:10,  2.69it/s, Loss/Training=0.533]0:   0%|          | 2/1000 [00:01<06:10,  2.69it/s, Loss/Training=0.396]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.396]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.421]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.478]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.465]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.532]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.305]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.463]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.3]  0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.353]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.469]0:   0%|          | 3/1000 [00:01<05:50,  2.85it/s, Loss/Training=0.328]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.328]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.256]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.409]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.387]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.296]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.419]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.384]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.167]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.367]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.312]0:   0%|          | 4/1000 [00:01<05:38,  2.94it/s, Loss/Training=0.412]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.412]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.343]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.406]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.399]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.206]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.204]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.47] 0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.419]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.66] 0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.207]0:   0%|          | 5/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.41] 0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.41]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.511]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.36] 0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.322]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.216]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.275]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.437]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.133]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.466]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.561]0:   1%|          | 6/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.328]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.328]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.39] 0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.308]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.382]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.523]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.412]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.518]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.419]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.406]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.269]0:   1%|          | 7/1000 [00:02<05:30,  3.00it/s, Loss/Training=0.383]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.383]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.177]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.484]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.64] 0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.493]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.382]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.497]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.279]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.219]0:   1%|          | 8/1000 [00:02<05:26,  3.03it/s, Loss/Training=0.449]0:   1%|          | 8/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.52] 0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.52]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.531]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.359]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.364]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.413]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.573]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.187]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.46] 0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.529]0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.34] 0:   1%|          | 9/1000 [00:03<05:26,  3.03it/s, Loss/Training=0.419]0:   1%|          | 9/1000 [00:03<06:23,  2.58it/s, Loss/Training=0.419]
:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp7c5869
[INFO 2025-01-27 15:49:26,878] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmp7c5869
Current state after restoring: {'_iteration': 2200, '_timesteps_total': None, '_time_total': 86.57642340660095, '_episodes_total': None}
[INFO 2025-01-27 15:49:26,878] trainable.py: 913  Current state after restoring: {'_iteration': 2200, '_timesteps_total': None, '_time_total': 86.57642340660095, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.43]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.311]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.221]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.332]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.389]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.323]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.301]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.249]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.317]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.283]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.283]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.336]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.341]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.412]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.316]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.257]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.509]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.501]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.228]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.518]0:   0%|          | 1/1000 [00:00<07:19,  2.27it/s, Loss/Training=0.553]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.553]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.409]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.452]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.401]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.293]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.489]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.272]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.419]0:   0%|          | 2/1000 [00:00<06:12,  2.68it/s, Loss/Training=0.516]0:   0%|          | 2/1000 [00:01<06:12,  2.68it/s, Loss/Training=0.382]0:   0%|          | 2/1000 [00:01<06:12,  2.68it/s, Loss/Training=0.378]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.378]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.469]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.355]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.295]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.282]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.396]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.468]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.512]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.41] 0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.535]0:   0%|          | 3/1000 [00:01<05:50,  2.84it/s, Loss/Training=0.451]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.451]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.276]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.426]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.569]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.475]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.647]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.402]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.471]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.281]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.273]0:   0%|          | 4/1000 [00:01<05:39,  2.94it/s, Loss/Training=0.408]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.408]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.554]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.662]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.522]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.188]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.524]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.19] 0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.579]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.438]0:   0%|          | 5/1000 [00:01<05:34,  2.97it/s, Loss/Training=0.604]0:   0%|          | 5/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.358]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.358]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.493]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.469]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.573]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.255]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.398]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.413]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.583]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.392]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.277]0:   1%|          | 6/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.594]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.594]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.356]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.416]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.407]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.397]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.293]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.403]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.379]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.436]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.433]0:   1%|          | 7/1000 [00:02<05:34,  2.97it/s, Loss/Training=0.38] 0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.38]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.471]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.464]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.716]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.277]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.414]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.291]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.326]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.416]0:   1%|          | 8/1000 [00:02<05:33,  2.97it/s, Loss/Training=0.304]0:   1%|          | 8/1000 [00:03<05:33,  2.97it/s, Loss/Training=0.497]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.497]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.537]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.5]  0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.583]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.368]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.343]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.308]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.379]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.285]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.357]0:   1%|          | 9/1000 [00:03<05:28,  3.02it/s, Loss/Training=0.358]:actor_name:ray_tune_trainable
Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpade19e
[INFO 2025-01-27 15:49:51,395] trainable.py: 904  Restored on 10.12.92.124 from checkpoint: /home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/ray_results/PBT fashion_mnist_pbt/ray_tune_trainable_5ace2_00001_1_2025-01-27_15-38-20/checkpoint_tmpade19e
Current state after restoring: {'_iteration': 2300, '_timesteps_total': None, '_time_total': 90.53388118743896, '_episodes_total': None}
[INFO 2025-01-27 15:49:51,395] trainable.py: 913  Current state after restoring: {'_iteration': 2300, '_timesteps_total': None, '_time_total': 90.53388118743896, '_episodes_total': None}
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'data.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/datasets.py:126: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  to.load(os.path.join(root, 'targets.pt')))
/home/scs_deal_learning/users/mchowdhu/OptimisingWeightUpdateHyperparameters/train.py:770: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = to.load(save_file)
0:   0%|          | 0/1000 [00:00<?, ?it/s]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.296]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.34] 0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.376]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.261]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.552]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.338]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.541]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.221]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.362]0:   0%|          | 0/1000 [00:00<?, ?it/s, Loss/Training=0.221]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.221]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.526]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.433]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.311]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.312]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.364]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.48] 0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.4] 0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.292]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.502]0:   0%|          | 1/1000 [00:00<07:11,  2.32it/s, Loss/Training=0.505]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.505]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.381]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.343]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.249]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.402]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.382]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.315]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.419]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.209]0:   0%|          | 2/1000 [00:00<06:07,  2.71it/s, Loss/Training=0.234]0:   0%|          | 2/1000 [00:01<06:07,  2.71it/s, Loss/Training=0.206]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.206]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.43] 0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.643]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.648]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.253]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.39] 0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.488]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.351]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.251]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.425]0:   0%|          | 3/1000 [00:01<05:45,  2.89it/s, Loss/Training=0.478]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.478]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.4]  0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.393]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.28] 0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.374]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.221]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.479]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.608]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.271]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.464]0:   0%|          | 4/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.448]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.448]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.271]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.61] 0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.342]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.52] 0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.353]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.325]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.383]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.266]0:   0%|          | 5/1000 [00:01<05:40,  2.92it/s, Loss/Training=0.44] 0:   0%|          | 5/1000 [00:02<05:40,  2.92it/s, Loss/Training=0.46]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.46]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.649]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.303]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.432]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.454]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.574]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.495]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.452]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.396]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.382]0:   1%|          | 6/1000 [00:02<05:32,  2.99it/s, Loss/Training=0.336]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.336]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.244]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.448]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.235]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.385]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.233]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.342]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.289]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.297]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.395]0:   1%|          | 7/1000 [00:02<05:28,  3.02it/s, Loss/Training=0.385]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.385]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.28] 0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.399]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.35] 0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.442]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.159]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.364]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.418]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.206]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.184]0:   1%|          | 8/1000 [00:02<05:26,  3.04it/s, Loss/Training=0.439]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.439]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.264]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.18] 0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.276]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.411]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.418]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.392]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.329]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.365]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.242]0:   1%|          | 9/1000 [00:03<05:22,  3.08it/s, Loss/Training=0.282]:actor_name:ray_tune_trainable
